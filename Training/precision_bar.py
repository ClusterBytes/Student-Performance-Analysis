import matplotlib.pyplot as plt
import numpy as np

logistic = [0.5455100592387954, 0.9212259982325057, 0.8786267262930897, 0.9201237600253453, 0.9241510375674274, 0.8077435734307166, 0.606872123035402, 0.47063149771355867, 0.4963143182312005, 0.750029787428264, 0.7261160466548443, 0.8500812478303983, 0.8554284025877728, 0.8528118426674555, 0.4971619870798825, 0.5841231063110751, 0.845253045846721, 0.6266841955345209, 0.5764250778958645, 0.8814571063177947, 0.5970703268787213, 0.5944263650633204, 0.8115707949254668, 0.802398962848404, 0.6325677745679597, 0.6794118415929695, 0.6325048433333693, 0.6579920829624785, 0.7045309446407421, 0.9957165215958703, 0.9957183162491317, 0.508135340737179, 0.5223956421784166, 0.7043714677587231, 0.6564846308070834, 0.7583281717935391, 0.7147536651748929, 0.5332983129804982, 0.6620878170311132, 0.8340709575041128, 0.7904636947127971, 0.8931849609985597]
decision_tree = [0.5496152600487606, 0.9198667220546463, 0.9136394888340788, 0.9406234213888807, 0.939091819243663, 0.854073118278507, 0.5122269564538431, 0.5139252012854252, 0.5522396351410988, 0.7372021735959083, 0.972885032537961, 0.8754187410512126, 0.9334438458625008, 0.9539105146480418, 0.5258198025998205, 0.9381933684536722, 1.0, 0.7663867134370826, 0.597065107670849, 1.0, 0.5952420728124512, 0.8703700493288347, 0.9967462039045553, 1.0, 0.7840365852245079, 0.8018232617983991, 0.7642310391132292, 0.7645649528924268, 0.7981841190301401, 1.0, 0.9872609143676961, 0.5186417970566262, 0.5233806365826124, 0.8538517158907615, 0.7928088398616154, 0.7347905257328505, 0.8790285094515029, 0.4921207402445545, 0.9595083152566883, 0.9978308026030369, 0.8403839664794112, 0.9314729275658202]
svm = [0.5732325091948056, 0.9433995401164444, 0.8740382297866028, 0.9242507912521805, 0.9449369746861088, 0.8192025617188307, 0.6090119457022068, 0.5364972687508123, 0.5426744634398103, 0.7828728531813025, 0.9020138077479926, 0.8663206130422599, 0.9042037050102628, 0.9000086554520917, 0.5296836407696242, 0.8250649469202671, 0.9297740788289285, 0.7076007284510302, 0.6169466589986039, 0.9638478595987848, 0.5954143640500604, 0.7618022291108456, 0.9311101486301759, 0.9207426918706745, 0.7217342310617798, 0.7463811086035835, 0.7260773173519077, 0.7228560181412037, 0.719694107627039, 0.9957165215958703, 0.9957183162491317, 0.4950254666894906, 0.5441014573581437, 0.7700858179127001, 0.7620480708333204, 0.7937268276403772, 0.8306189435472785, 0.5657391116552482, 0.8798932087435342, 0.9379051388413187, 0.8223777445365914, 0.9140997830802603]
random_forest = [0.584382683371464, 0.9422230256286657, 0.8717304759651923, 0.9201237600253453, 0.9379065214035601, 0.825787761773362, 0.6610768023958113, 0.5034740209002305, 0.5499375452197605, 0.7733153766288017, 0.9374769933609414, 0.8951994102051521, 0.9280436964818743, 0.9135179118009583, 0.5036742665181985, 0.8428080776779259, 0.9648240407459495, 0.6790405076739133, 0.6183081502888121, 0.9858016170380597, 0.6610616392161843, 0.7836757040674656, 0.9785097374511765, 0.9559568570739938, 0.7244181161531995, 0.7305632520542562, 0.697005591696339, 0.7048494665883903, 0.7573320344028368, 0.9957165215958703, 0.9957183162491317, 0.5141018150255067, 0.5485916526227406, 0.7410084039345695, 0.7657918622388181, 0.7663597401522745, 0.8489128734348776, 0.5119743265622487, 0.8896084642717594, 0.9668594842130634, 0.82859637004008, 0.8933101395840182]

labels=['G'+str(i) for i in range(1,43)]
x = np.arange(len(labels))
width = 0.2
width1=0.1

fig, ax = plt.subplots()
rects1 = ax.bar(x - 1.5*width, logistic, width1, label='Logistic Regression')
rects2 = ax.bar(x - 0.5*width, decision_tree, width1, label='Decision Tree')
rects3 = ax.bar(x + 0.5*width, svm, width1, label='SVM')
rects4 = ax.bar(x + 1.5*width, random_forest, width1, label='Random Forest')

ax.set_ylim([0, 1.2])
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()
ax.set_title('Precision')
ax.set_xlabel('Labels')
ax.set_ylabel('Precision')

fig.tight_layout()

plt.show()