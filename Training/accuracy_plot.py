import matplotlib.pyplot as plt

logistic = [0.6442516268980477, 0.9262472885032538, 0.9175704989154013, 0.9479392624728851, 0.9544468546637744, 0.8698481561822126, 0.5900216919739696, 0.5075921908893709, 0.6355748373101953, 0.7830802603036876, 0.7613882863340564, 0.8980477223427332, 0.8611713665943601, 0.8698481561822126, 0.5921908893709328, 0.6442516268980477, 0.8806941431670282, 0.7331887201735358, 0.6572668112798264, 0.911062906724512, 0.6420824295010846, 0.5856832971800434, 0.8351409978308026, 0.8091106290672451, 0.7613882863340564, 0.7440347071583514, 0.7396963123644251, 0.7396963123644251, 0.7570498915401301, 0.9956616052060737, 0.9956616052060737, 0.6095444685466378, 0.5770065075921909, 0.8264642082429501, 0.7678958785249458, 0.7982646420824295, 0.7180043383947939, 0.5856832971800434, 0.7223427331887202, 0.89587852494577, 0.8286334056399133, 0.93058568329718]
decision_tree = [0.5206073752711496, 0.911062906724512, 0.89587852494577, 0.9479392624728851, 0.9370932754880694, 0.8590021691973969, 0.5401301518438177, 0.4967462039045553, 0.5357917570498916, 0.754880694143167, 0.9696312364425163, 0.8806941431670282, 0.9414316702819957, 0.9436008676789588, 0.5227765726681128, 0.9349240780911063, 1.0, 0.7635574837310195, 0.5748373101952278, 1.0, 0.5748373101952278, 0.8655097613882863, 1.0, 1.0, 0.7917570498915402, 0.7570498915401301, 0.7418655097613883, 0.7613882863340564, 0.7700650759219089, 1.0, 0.9869848156182213, 0.5357917570498916, 0.5292841648590022, 0.8394793926247288, 0.7744034707158352, 0.7245119305856833, 0.8785249457700651, 0.5075921908893709, 0.9631236442516269, 0.9956616052060737, 0.8286334056399133, 0.9219088937093276]
svm = [0.6268980477223427, 0.9392624728850325, 0.911062906724512, 0.9479392624728851, 0.9501084598698482, 0.8698481561822126, 0.6008676789587852, 0.5314533622559653, 0.6420824295010846, 0.7917570498915402, 0.8980477223427332, 0.9002169197396963, 0.9023861171366594, 0.89587852494577, 0.5835140997830802, 0.8264642082429501, 0.9262472885032538, 0.7527114967462039, 0.6681127982646421, 0.9674620390455532, 0.6550976138828634, 0.754880694143167, 0.9327548806941431, 0.911062906724512, 0.7744034707158352, 0.7657266811279827, 0.754880694143167, 0.7613882863340564, 0.754880694143167, 0.9956616052060737, 0.9956616052060737, 0.5986984815618221, 0.5835140997830802, 0.8373101952277657, 0.7982646420824295, 0.8047722342733189, 0.8264642082429501, 0.6008676789587852, 0.8720173535791758, 0.9436008676789588, 0.8264642082429501, 0.9197396963123644]
random_forest = [0.6616052060737527, 0.9414316702819957, 0.9023861171366594, 0.9479392624728851, 0.9544468546637744, 0.8741865509761388, 0.6355748373101953, 0.5249457700650759, 0.648590021691974, 0.7874186550976139, 0.9392624728850325, 0.9067245119305857, 0.9219088937093276, 0.9219088937093276, 0.6030368763557483, 0.8741865509761388, 0.9761388286334056, 0.754880694143167, 0.6767895878524945, 0.982646420824295, 0.6637744034707158, 0.8004338394793926, 0.9848156182212582, 0.9501084598698482, 0.7830802603036876, 0.7635574837310195, 0.7613882863340564, 0.7678958785249458, 0.7809110629067245, 0.9956616052060737, 0.9956616052060737, 0.6073752711496746, 0.6095444685466378, 0.8308026030368764, 0.8047722342733189, 0.7917570498915402, 0.8503253796095445, 0.5770065075921909, 0.911062906724512, 0.9761388286334056, 0.8394793926247288, 0.9262472885032538]

labels=['G'+str(i) for i in range(1,43)]

plt.plot(labels, logistic, label='Logistic Regression')
plt.plot(labels, decision_tree, label='Decision Tree')
plt.plot(labels, svm, label='SVM')
plt.plot(labels, random_forest, label='Random Forest')

plt.ylim([0, 1.2])
plt.legend()
plt.title('Accuracies')
plt.xlabel('Labels')
plt.ylabel('Accuracy')

plt.show()
